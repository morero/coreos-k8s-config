#cloud-config

hostname: "MYHOSTNAME"
write_files:
  - path: /etc/modprobe.d/bonding.conf
    content: |
      # Prevent kernel from automatically creating bond0 when the module is loaded.
      # This allows systemd-networkd to create and apply options to bond0.
      options bonding max_bonds=0
  - path: /etc/systemd/network/10-e.network
    permissions: 0644
    owner: root
    content: |
      [Match]
      Name=e*

      [Network]
      Bond=bond0
  - path: /etc/systemd/network/20-bond.netdev
    permissions: 0644
    owner: root
    content: |
      [NetDev]
      Name=bond0
      Kind=bond

      [Bond]
      Mode=0 # defaults to balance-rr
      MIIMonitorSec=100
  - path: /etc/udev/rules.d/50-rbd.rules
    content: |
      KERNEL=="rbd[0-9]*", ENV{DEVTYPE}=="disk", PROGRAM="/opt/bin/ceph-rbdnamer %k", SYMLINK+="rbd/%c{1}/%c{2}"
      KERNEL=="rbd[0-9]*", ENV{DEVTYPE}=="partition", PROGRAM="/opt/bin/ceph-rbdnamer %k", SYMLINK+="rbd/%c{1}/%c{2}-part%n"
  - path: /opt/bin/ceph
    permissions: "0755"
    content: |
      #!/bin/sh
      /usr/bin/docker run --rm -v /etc/ceph:/etc/ceph ceph/base ceph "$@"
  - path: /opt/bin/ceph-disk
    permissions: "0755"
    content: |
      #!/bin/sh
      /usr/bin/docker run --rm --privileged=true -v /etc/ceph:/etc/ceph -v /dev:/dev ceph/base ceph-disk "$@"
  - path: /opt/bin/ceph-rbdnamer
    permissions: "0755"
    content: |
      #!/bin/sh
      DEV=$1
      NUM=`echo $DEV | sed 's#p.*##g' | tr -d 'a-z'`
      POOL=`cat /sys/devices/rbd/$NUM/pool`
      IMAGE=`cat /sys/devices/rbd/$NUM/name`
      SNAP=`cat /sys/devices/rbd/$NUM/current_snap`
      if [ "$SNAP" = "-" ]; then
          echo -n "$POOL $IMAGE"
      else
          echo -n "$POOL $IMAGE@$SNAP"
      fi
  - path: /opt/bin/rados
    permissions: "0755"
    content: |
      #!/bin/sh
      /usr/bin/docker run --rm -v /etc/ceph:/etc/ceph ceph/base rados "$@"
  - path: /opt/bin/rbd
    permissions: "0755"
    content: |
      #!/bin/sh
      /usr/bin/docker run --rm -v /etc/ceph:/etc/ceph -v /sys:/sys --net=host --privileged=true ceph/base rbd "$@"
  - path: /etc/kubernetes/manifests/kube-proxy.yaml
    content: |
      apiVersion: v1
      kind: Pod
      metadata:
        name: kube-proxy
        namespace: kube-system
      spec:
        hostNetwork: true
        containers:
        - name: kube-proxy
          image: quay.io/coreos/hyperkube:HYPERKUBE_VERSION
          command:
          - /hyperkube
          - proxy
          - --master=https://MASTER_IP
          - --kubeconfig=/etc/kubernetes/worker-kubeconfig.yaml
          - --proxy-mode=iptables
          securityContext:
            privileged: true
          volumeMounts:
            - mountPath: /etc/ssl/certs
              name: "ssl-certs"
            - mountPath: /etc/kubernetes/worker-kubeconfig.yaml
              name: "kubeconfig"
              readOnly: true
            - mountPath: /etc/kubernetes/ssl
              name: "etc-kube-ssl"
              readOnly: true
        volumes:
          - name: "ssl-certs"
            hostPath:
              path: "/usr/share/ca-certificates"
          - name: "kubeconfig"
            hostPath:
              path: "/etc/kubernetes/worker-kubeconfig.yaml"
          - name: "etc-kube-ssl"
            hostPath:
              path: "/etc/kubernetes/ssl"

  - path: /etc/kubernetes/worker-kubeconfig.yaml
    content: |
      apiVersion: v1
      kind: Config
      clusters:
      - name: local
        cluster:
          certificate-authority: /etc/kubernetes/ssl/ca.pem
      users:
      - name: kubelet
        user:
          client-certificate: /etc/kubernetes/ssl/worker.pem
          client-key: /etc/kubernetes/ssl/worker-key.pem
      contexts:
      - context:
          cluster: local
          user: kubelet
        name: kubelet-context
      current-context: kubelet-context

  - path: /etc/kubernetes/cni/net.d/10-calico.conf
    content: |
      {
        "name": "calico",
        "type": "flannel",
        "delegate": {
          "type": "calico",
          "etcd_endpoints": "MYETCDENDPOINTS",
          "log_level": "none",
          "log_level_stderr": "info",
          "hostname": "MYIPADDRESS",
          "policy": {
            "type": "k8s",
            "k8s_api_root": "https://MASTER_IP:443/api/v1/",
            "k8s_client_key": "/etc/kubernetes/ssl/worker-key.pem",
            "k8s_client_certificate": "/etc/kubernetes/ssl/worker.pem"
          }
        }
      }
  - path: /etc/ssh/sshd_config
    permissions: 0600
    owner: root:root
    content: |
      # Use most defaults for sshd configuration.
      UsePrivilegeSeparation sandbox
      Subsystem sftp internal-sftp
      ClientAliveInterval 180
      UseDNS no
      UsePAM yes
      PrintMotd no # handled by PAM

      PermitRootLogin no
      AllowUsers core
      PasswordAuthentication no
      ChallengeResponseAuthentication no
coreos:
  flannel:
    etcd_endpoints: "MYETCDENDPOINTS"
    interface: "MYIPADDRESS"
  etcd2:
    name: "MYHOSTNAME"
    advertise-client-urls: "http://MYIPADDRESS:2379"
    initial-advertise-peer-urls: "http://MYIPADDRESS:2380"
    initial-cluster-token: "etcd-cluster-1"
    listen-client-urls: "http://0.0.0.0:2379,http://0.0.0.0:4001"
    listen-peer-urls: "http://0.0.0.0:2380"
  update:
    reboot-strategy: "etcd-lock"
  units:
    - name: systemd-timesyncd.service
      command: start
      enable: true
    - name: ntpd.service
      command: stop
      mask: true
    - name: etcd2.service
      command: start
    - name: docker.service
      drop-ins:
        - name: 40-flannel.conf
          content: |
            [Unit]
            Requires=flanneld.service
            After=flanneld.service
    - name: kubelet.service
      command: start
      enable: true
      content: |
        [Service]
        ExecStartPre=/usr/bin/mkdir -p /etc/kubernetes/manifests

        Environment=KUBELET_VERSION=HYPERKUBE_VERSION
        ExecStart=/usr/lib/coreos/kubelet-wrapper \
          --api-servers=https://MASTER_IP \
          --network-plugin-dir=/etc/kubernetes/cni/net.d \
          --network-plugin=cni \
          --register-node=true \
          --allow-privileged=true \
          --config=/etc/kubernetes/manifests \
          --hostname-override=MYIPADDRESS \
          --cluster-dns=10.3.0.10 \
          --cluster-domain=cluster.local \
          --kubeconfig=/etc/kubernetes/worker-kubeconfig.yaml \
          --tls-cert-file=/etc/kubernetes/ssl/worker.pem \
          --tls-private-key-file=/etc/kubernetes/ssl/worker-key.pem
        Restart=always
        RestartSec=10
        [Install]
        WantedBy=multi-user.target
    - name: calico-node.service
      command: start
      enable: true
      content: |
        [Unit]
        Description=Calico node for network policy
        Requires=network-online.target
        After=network-online.target

        [Service]
        Slice=machine.slice
        Environment=CALICO_DISABLE_FILE_LOGGING=true
        Environment=HOSTNAME=MYIPADDRESS
        Environment=IP=MYIPADDRESS
        Environment=FELIX_FELIXHOSTNAME=MYIPADDRESS
        Environment=CALICO_NETWORKING=false
        Environment=NO_DEFAULT_POOLS=true
        Environment=ETCD_ENDPOINTS=http://MYIPADDRESS:2379
        ExecStart=/usr/bin/rkt run --inherit-env --stage1-from-dir=stage1-fly.aci \
        --volume=modules,kind=host,source=/lib/modules,readOnly=false \
        --mount=volume=modules,target=/lib/modules \
        --trust-keys-from-https quay.io/calico/node:v0.22.0
        KillMode=mixed
        Restart=always
        TimeoutStartSec=0

        [Install]
        WantedBy=multi-user.target
    - name: data.mount
      command: start
      content: |
        [Mount]
        What=/dev/sdb
        Where=/data
        Type=btrfs
ssh_authorized_keys:
  - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDAaWHESLrzhMX4MmMwc/SmUtH35dDvvbS4XaQwGQUKR/SjSDaHaJS5ErWY2/Uk/xjDykyTFUlIVD6mcueHmHEhmB0YDNN3nsmA6VIht4qr6Y17u8PPAvt72QUaHnq6G7WmLeVH5FKLl1tAKnZvpIPGdwFNWNmuBxr1TPjpnKqnxFT4qkX96YFw80ZxMlqqgpUgwn/RRt7/jknAM1BtyG253xWoklaqQ9n4gYeaAuPulx3rln6aeTeXCQbjJFcU64LtX9nAX2aXffP1KqY7z7x8T1tcVwmBlsabB0vWEqF9aRvWRTkvSzB6XuSYYJSxvA9+JsvV4dRod38NfOHY9a3J
